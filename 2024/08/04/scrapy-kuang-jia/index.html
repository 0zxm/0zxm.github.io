<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="scrapy框架, 0zxm">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>scrapy框架 | 0zxm</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 7.2.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">0zxm</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">0zxm</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/16.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">scrapy框架</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/python/">
                                <span class="chip bg-color">python</span>
                            </a>
                        
                            <a href="/tags/scrapy/">
                                <span class="chip bg-color">scrapy</span>
                            </a>
                        
                            <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/">
                                <span class="chip bg-color">数据持久化存储</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E7%88%AC%E8%99%AB/" class="post-category">
                                爬虫
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-08-04
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    42 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Scrapy框架简介"><a href="#Scrapy框架简介" class="headerlink" title="Scrapy框架简介"></a>Scrapy框架简介</h2><p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/">Scrapy官方文档</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1jx411b7E3/">B站黑马教程</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Db4y1m7Ho/">B站尚硅谷教程</a></p>
<p><a href="http://0zxm.github.io/PDFs/%E7%88%AC%E8%99%AB%E4%BB%A3%E7%A0%81.zip">代码文件</a></p>
<h3 id="scrapy框架"><a href="#scrapy框架" class="headerlink" title="scrapy框架"></a>scrapy框架</h3><ul>
<li>Scrapy是用纯Python实现一个为了爬取网站数据、提取结构性数据而编写的应用框架，用途非常广泛。</li>
<li>框架的力量，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片，非常之方便。</li>
<li>Scrapy 使用了 <code>Twisted[&#39;twrstrd]</code>(其主要对手是Tornado)异步网络框架来处理网络通讯，可以加快我们的下载速度，不用自己去实现异步框架，并且包含了各种中间件接口，可以灵活的完成各种需求</li>
</ul>
<h3 id="scrapy是什么？"><a href="#scrapy是什么？" class="headerlink" title="scrapy是什么？"></a>scrapy是什么？</h3><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理<br>或存储历史数据等一系列的程序中。</p>
<h3 id="安装scrapy"><a href="#安装scrapy" class="headerlink" title="安装scrapy"></a>安装scrapy</h3><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">安装非Python的依赖 
sudo apt-get install python-dev python-pip libxm12-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev(Ubuntu下安装)

pip install scrapy <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>安装过程中出错：</p>
<ol>
<li><p>如果安装有错误！！！！</p>
 <pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">pip install Scrapy
building 'twisted.test.raiser' extension
error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ 
Build Tools": http://landinghub.visualstudio.com/visual‐cpp‐build‐tools<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<p>解决方案：<br><a target="_blank" rel="noopener" href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted">http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted</a>         </p>
<p>下载twisted对应版本的<code>whl</code>文件（如我的Twisted‐17.5.0‐cp36‐cp36m‐win_amd64.whl），cp后面是python版本，amd64代表64位，运行命令：<br>pip install C:\Users...\Twisted‐17.5.0‐cp36‐cp36m‐win_amd64.whl        </p>
<p>pip install Scrapy        </p>
<ol start="2">
<li>如果再报错: python ‐m pip install ‐‐upgrade pip            </li>
<li>如果再报错  win32</li>
</ol>
<p>解决方法：<br>   pip install pypiwin32      </p>
<ol start="4">
<li>再报错：使用anaconda<br> 使用步骤：        <ul>
<li>打开anaconda           </li>
<li>点击environments            </li>
<li>点击not installed             </li>
<li>输入scrapy             </li>
<li>apply(应用)             </li>
<li>在<strong>pycharm</strong>中选择anaconda的环境</li>
</ul>
</li>
</ol>
<h2 id="Scrapy架构图-绿线是数据流向"><a href="#Scrapy架构图-绿线是数据流向" class="headerlink" title="Scrapy架构图(绿线是数据流向)"></a>Scrapy架构图(绿线是数据流向)</h2><img src="/2024/08/04/scrapy-kuang-jia/scrapy架构图.png" alt="image" style="zoom: 67%;">

<ul>
<li><code>Scrapy Engine</code>(引擎):负责<code>Spider</code>、<code>Item Pipeline</code>、<code>Downloader</code>、<code>Scheduler</code> 中间的通讯，信号、数据传递等。</li>
<li><code>Scheduler</code>(调度器):它负责接受<strong>引擎</strong>发送过来的Request请求，并按照一定的方式进行整理排列，入队，当<strong>引擎</strong> 需要时，交还给<strong>引擎</strong>。</li>
<li><code>Downloader</code>(下载器):负责下载 <code>Scrapy Engine</code>(引擎)发送的所有Requests请求，并将其获取到的Responses交还给 <code>Scrapy Engine</code>(引擎)，由引擎交给 <code>Spider</code> 来处理。</li>
<li><code>Item Pipeline</code>(管道):它负责处理 <code>Spider</code> 中获取到的 Item(有用的数据，需要存储的)，并进行进行后期处理(详细分析、过滤、存储等)的地方.</li>
<li><code>Downloader middlewares</code>(下载中间件):你可以当作是一个可以自定义扩展下载功能的组件。</li>
<li><code>Spider Middlewares</code>(spider中间件):你可以理解为是一个可以自定扩展和操作<code>引擎</code>和<code>Spider</code>中间<strong>通信</strong>的功能组件(比如进入<code>Spider</code>的<strong>Responses</strong>;和从<code>Spider</code>出去的<strong>Requests</strong>)</li>
</ul>
<h3 id="scrapy架构流程"><a href="#scrapy架构流程" class="headerlink" title="scrapy架构流程"></a>scrapy架构流程</h3><ul>
<li><p>（1）<strong>引擎</strong>                       ‐‐‐》自动运行，无需关注，会自动组织所有的请求对象，分发给下载器              </p>
</li>
<li><p>（2）<strong>下载器</strong>    	         ‐‐‐》从引擎处获取到请求对象后，请求数据                     </p>
</li>
<li><p>（3）<strong>Spiders</strong> 	         ‐‐‐》Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
</li>
<li><p>（4）<strong>调度器</strong>    	          ‐‐‐》有自己的调度规则，无需关注                     </p>
</li>
<li><p>（5）<strong>管道（Item Pipeline）</strong>       ‐‐‐》最终处理数据的管道，会预留接口供我们处理数据.当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。每个itempipeline组件(有时称之为<strong>“Item Pipeline”</strong>)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。</p>
</li>
<li><p>以下是item pipeline的一些典型应用：</p>
<ol>
<li><p>清理HTML数据</p>
</li>
<li><p>验证爬取的数据(检查item包含某些字段)</p>
</li>
<li><p>查重(并丢弃)</p>
</li>
<li><p>将爬取结果保存到数据库中</p>
</li>
</ol>
</li>
</ul>
<p><img src="/2024/08/04/scrapy-kuang-jia/scrapy%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="image-20240802222000457"></p>
<h2 id="Scrapy项目的运行流程"><a href="#Scrapy项目的运行流程" class="headerlink" title="Scrapy项目的运行流程"></a>Scrapy项目的运行流程</h2><p>代码写好，程序开始运行 </p>
<ol>
<li>引擎: Hi!Spider,你要处理哪一个网站?</li>
<li>Spider: 老大要我处理xxxx.com。</li>
<li>引擎: 你把第一个需要处理的URL给我吧。</li>
<li>Spider: 给你，第一个URL是 xxxxxxx.com。</li>
<li>引擎: Hi!调度器，我这有request请求,你帮我排序入队一下</li>
<li>调度器: 好的，正在处理,你等一下。</li>
<li>引擎: Hi!调度器，把你处理好的request请求给我。</li>
<li>调度器: 给你，这是我处理好的request</li>
<li>引擎: Hi!下载器，你按照老大的<code>下载中间件</code>的设置帮我下载一下这个request请求</li>
<li>下载器: 好的!给你，这是下载好的东西。(如果失败:sorry，这个request下载失败了。然后<code>引擎</code>告诉<code>调度器</code>，这个request下载失败了，你记录一下，我们待会儿再下载)</li>
<li>引擎: Hi! spider，这是下载好的东西，并且已经按照老大的<code>下载中间件</code>处理过了，你自己处理一下(注意!这儿responses默认是交给 <strong>def parse()</strong> 这个函数处理的)</li>
<li>Spider: (处理完毕数据之后对于需要跟进的URL)，Hi!引擎，我这里有两个结果，这个是我需要<br>跟进的URL，还有这个是我获取到的Item数据。</li>
<li>引擎: Hi !管道 我这儿有个Item你帮我处理一下!调度器!这是需要跟进URL你帮我处理下。然后从第四步开始循环，直到获取完老大需要全部信息。</li>
<li>管道、调度器: 好的，现在就做!</li>
</ol>
<p><strong>注意!只有当<code>调度器</code>中不存在任何request了,整个程序才会停止，(也就是说,对于下载失败的URL,Scrapy也会重新下载。)</strong></p>
<h2 id="制作Scrapy爬虫一共四步"><a href="#制作Scrapy爬虫一共四步" class="headerlink" title="制作Scrapy爬虫一共四步"></a>制作Scrapy爬虫一共四步</h2><ul>
<li><p>新建项目(scrapy start project xxx):新建一个新的爬虫项词。</p>
</li>
<li><p>明确目标(编写items.py):明确你想要抓取的目标。</p>
</li>
<li><p>制作爬虫(spiders&#x2F;xxspider.py):制作爬虫开始爬取网页。</p>
</li>
<li><p>存储内容(pipelines.py):设计管道存储爬取内容。</p>
</li>
</ul>
<h3 id="1-创建scrapy项目："><a href="#1-创建scrapy项目：" class="headerlink" title="1.创建scrapy项目："></a>1.创建scrapy项目：</h3><pre><code>  终端输入  `scrapy startproject  项目名称`    
</code></pre>
<p>​	 </p>
<h3 id="2-项目组成："><a href="#2-项目组成：" class="headerlink" title="2.项目组成："></a>2.项目组成：</h3><p>​          spiders<br>​              <strong>init</strong>.py<br>​              自定义的爬虫文件.py        ‐‐‐》由我们自己创建，是实现爬虫核心功能的文件<br>​          <strong>init</strong>.py                  </p>
<p>​          items.py                     ‐‐‐》定义数据结构的地方，是一个继承自scrapy.Item的类<br>​          middlewares.py               ‐‐‐》中间件   代理<br>​          pipelines.py   	      ‐‐‐》管道文件，里面只有一个类，用于处理下载数据的后续处					    理,默认是300优先级，值越小优先级越高（1‐1000）                                       </p>
<p>​          settings.py   	       ‐‐‐》配置文件  比如：是否遵守robots协议，User‐Agent					    定义   </p>
<h3 id="3-创建爬虫文件："><a href="#3-创建爬虫文件：" class="headerlink" title="3.创建爬虫文件："></a>3.创建爬虫文件：</h3><ul>
<li><p>（1）跳转到spiders文件夹   cd 目录名字&#x2F;目录名字&#x2F;spiders           	</p>
</li>
<li><p>（2）scrapy genspider 爬虫名字 网页的域名             </p>
</li>
<li><p>爬虫文件的基本组成：</p>
<ul>
<li>继承scrapy.Spider类                                		<ol>
<li>name &#x3D; ‘baidu’        ‐‐‐》 运行爬虫文件时使用的名字</li>
<li>allowed_domains       ‐‐‐》爬虫允许的域名，在爬取的时候，如果不是此域名之下的url，会被过滤掉</li>
<li>start_urls            ‐‐‐》 声明了爬虫的起始地址，可以写多个url，一般是一个                        </li>
<li>parse(self, response) ‐‐‐》解析数据的回调函数<ol>
<li>response.text         ‐‐‐》响应的是字符串</li>
<li>response.body         ‐‐‐》响应的是二进制文件</li>
<li>response.xpath()      –‐》xpath方法的返回值类型是selector列表</li>
<li>extract()             ‐‐‐》提取的是selector对象的是data</li>
<li>extract_first()       ‐‐‐》提取的是selector列表中的第一个数据</li>
</ol>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="4-运行爬虫文件"><a href="#4-运行爬虫文件" class="headerlink" title="4.运行爬虫文件:"></a>4.运行爬虫文件:</h3><pre><code>`scrapy crawl 爬虫名称`

注意:应在spiders文件夹内执行
</code></pre>
<h2 id="Scrapy框架终端基本命令"><a href="#Scrapy框架终端基本命令" class="headerlink" title="Scrapy框架终端基本命令"></a>Scrapy框架终端基本命令</h2><ul>
<li>scrapy bench 测试性能(pages&#x2F;min)</li>
</ul>
<p><img src="/2024/08/04/scrapy-kuang-jia/scrapy_fetch.png" alt="scrapy_fetch"></p>
<ul>
<li>scrapy fetch ‘<a target="_blank" rel="noopener" href="http://www.baidu.com’/">http://www.baidu.com’</a> 爬取百度页面的源代码,DEBUG信息(200)表示爬虫程序正常运行</li>
<li>genspider 创建爬虫</li>
<li>runspider 启动爬虫</li>
<li>shell 使用scrapy的shell环境</li>
<li>startproject 创建项目</li>
<li>version 显示版本</li>
<li>view 使用浏览器视图</li>
<li>list 显示当前项目有多少个爬虫程序</li>
</ul>
<h2 id="入门案例"><a href="#入门案例" class="headerlink" title="入门案例"></a>入门案例</h2><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul>
<li>创建一个Scrapy项目</li>
<li>定义提取的结构化数据(Item)</li>
<li>编写爬取网站的 Spider 并提取出结构化数据(Item)</li>
<li>编写 Item Pipelines 来存储提取到的Item(即结构化数据)</li>
</ul>
<h3 id="1-新建爬虫项目"><a href="#1-新建爬虫项目" class="headerlink" title="1.新建爬虫项目"></a>1.新建爬虫项目</h3><p>在开始爬取之前，必须创建一个新的Scrapy项目。进入自定义的项目目录中，运行下列命令<br><code>scrapy startproject mySpider</code></p>
<h3 id="2-新建爬虫"><a href="#2-新建爬虫" class="headerlink" title="2.新建爬虫"></a>2.新建爬虫</h3><p>跳转到mySpider&#x2F;mySpider&#x2F;spiders文件夹下</p>
<p><code>scrapy genspider 爬虫名 网页域名</code></p>
<p>网页域名的作用,让爬虫程序只在此域名下爬取</p>
<p>会在spiders文件夹下生成<code>爬虫名.py文件</code></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>	<span class="token comment">#Spider类</span>
    name <span class="token operator">=</span> <span class="token string">"itcast"</span>	<span class="token comment"># 爬虫名称</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.itcast.cn"</span><span class="token punctuation">]</span>	<span class="token comment"># 爬虫运行的域名</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"http://www.itcast.cn"</span><span class="token punctuation">]</span>	<span class="token comment"># 起始url,爬虫程序启动的第一次请求目的url</span>

    <span class="token triple-quoted-string string">"""处理响应数据的方法"""</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span>
        <span class="token comment"># pass</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>后面还会学习到<code>CrawlSpider</code>类</p>
<h3 id="3-运行和检测爬虫程序"><a href="#3-运行和检测爬虫程序" class="headerlink" title="3.运行和检测爬虫程序"></a>3.运行和检测爬虫程序</h3><ul>
<li><strong>先看项目能不能正常运行在修改代码</strong></li>
</ul>
<p><img src="/2024/08/04/scrapy-kuang-jia/crawl.png" alt="image-20240802130119274"></p>
<p>此时,输入scrapy会多一些可用指令</p>
<ul>
<li>scrapy check 爬虫名	检查爬虫是否正常</li>
<li>scrapy crawl 爬虫名        启动爬虫程序</li>
</ul>
<p><img src="/2024/08/04/scrapy-kuang-jia/%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84.png" alt="image-20240802132150074"></p>
<p>下面来简单介绍一下各个主要文件的作用:</p>
<ul>
<li>scrapy.cfg :项目的配置文件</li>
<li>Itcast&#x2F;:项目的Python模块，将会从这里引用代码</li>
<li>Itcast&#x2F;items.py:项目的目标文件</li>
<li>Itcast&#x2F;pipelines.py:项目的管道文件</li>
<li>Itcast&#x2F;settings.py:项目的设置文件</li>
<li>Itcast&#x2F;spiders&#x2F;:存储爬虫代码目录</li>
</ul>
<h3 id="4-明确目标-Itcast-items-py"><a href="#4-明确目标-Itcast-items-py" class="headerlink" title="4.明确目标(Itcast&#x2F;items.py)"></a>4.明确目标(Itcast&#x2F;items.py)</h3><p>我们打算抓取:<a target="_blank" rel="noopener" href="http://www.itcast.cn/channel/teacher.shtml">http://www.itcast.cn/channel/teacher.shtml</a> 网站里的所有讲师的姓名、职称和个人信息。</p>
<ol>
<li>打开mySpider目录下的items.py,</li>
<li>Item 定义结构化数据字段用来保存爬取到的数据，有点像Python中的dict，但是提供了一些额外的保护减少错误。</li>
<li>可以通过创建一个 <code>scrapy.Item</code> 类，并且定义类型为 <code>scrapy.Field</code> 的类属性来定义一个 Item (可以理解成类似于ORM的映射关系)。</li>
<li>接下来，创建一个 <code>ItcastItem</code>类，和构建item模型(model)。</li>
</ol>
<h3 id="5-制作爬虫"><a href="#5-制作爬虫" class="headerlink" title="5.制作爬虫"></a>5.制作爬虫</h3><h4 id="爬数据-Itcast-spiders-itcast-py"><a href="#爬数据-Itcast-spiders-itcast-py" class="headerlink" title="爬数据(Itcast&#x2F;spiders&#x2F;itcast.py)"></a>爬数据(Itcast&#x2F;spiders&#x2F;itcast.py)</h4><p>在当前目录下输入命令，将在 myspider&#x2F;spider 目录下创建一个名为 itcast 的爬虫，并指定爬取域的范围:<code>Scrapy genspider itcast &quot;itcast.cn&quot;</code></p>
<p>打开 <code>Itcast/spider</code> 目录里的 itcast.py，默认增加了下列代码</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>	
    name <span class="token operator">=</span> <span class="token string">"itcast"</span>	
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.itcast.cn"</span><span class="token punctuation">]</span>	
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"http://www.itcast.cn"</span><span class="token punctuation">]</span>	

    <span class="token triple-quoted-string string">"""处理响应数据的方法"""</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># pass</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>其实也可以由我们自行创建 <strong>itcast.py</strong> 并编写上面的代码，只不过使用命令可以免去编写固定代码的麻烦</p>
<p>要建立一个Spider，你必须用scrapy.Spider类创建一个子类，并确定了<strong>三个强制的属性</strong>和<strong>一个方法</strong>。</p>
<ul>
<li><p><code>name = “”</code>: 这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。</p>
</li>
<li><p><code>allow_domains = []</code>是搜索的域名范围，也就是爬虫的约束区域,规定爬虫只爬取这个域名下的网<br>  页，不存在的URL会被忽略。</p>
</li>
<li><p><code>start_ur1s = ()</code>:爬取的URL元祖&#x2F;列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些URL开始。其他子URL将会从这些起始URL中继承性生成。</p>
</li>
<li><p><code>parse(se1f，response)</code>:解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，主要作用如下:</p>
<ol>
<li>负责解析返回的网页数据(response.body)，提取结构化数据(生成item)</li>
<li>生成需要下一页的URL请求。</li>
</ol>
</li>
</ul>
<p>将start_urls的值修改为需要爬取的第一个url</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">start_urls <span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"http://ww.itcast.cn/channel/teacher.shtml"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>修改parse()方法</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"teacher.html"</span><span class="token punctuation">,</span><span class="token string">"w"</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>然后运行一下看看，在Itcast目录下执行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">scrapy crawl itcast<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>是的，就是 itcast,看上面代码，它是 <strong>ItcastSpider</strong> 类的 name 属性,也就是使用 <strong>scrapy genspider</strong> 命令的爬虫名。</p>
<p>一个Scrapy爬虫项目里，可以存在多个爬虫。各个爬虫在执行时，就是按照 name 属性来区分。</p>
<p>运行之后，如果打印的日志出现<code>[scrapy]INFO:Spider closed(finished)</code>，代表执行完成。之后当前文件夹中就出现了一个 teacher.html 文件，里面就是我们刚刚要爬取的网页的全部源代码信息</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 注意，Python2.x默认编码环境是ASCII码,当和取回的数据编码格式不一致时，可能会造成乱码;</span>
<span class="token comment"># 我们可以指定保存内容的编码格式，一般情况下，我们可以在代码最上方添加:</span>
<span class="token keyword">import</span> sys
<span class="token builtin">reload</span><span class="token punctuation">(</span>sys<span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>setdefaultencoding<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
<span class="token comment">#这三行代码是Python2.x里解决中文编码的万能钥匙，经过这么多年的吐槽后Python3学乖了，默认编码是Unicode了..</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="取数据"><a href="#取数据" class="headerlink" title="取数据"></a>取数据</h4><p>爬取整个网页完毕,接下来的就是取数据过程了,首先观察</p>
<p><img src="/2024/08/04/scrapy-kuang-jia/%E7%BD%91%E9%A1%B5%E7%BB%93%E6%9E%84.png"></p>
<p>很明显可以看出网页结构如下图所示</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>images/teacher/javaee/20220302113627师老师高级讲师2009年入行.jpg<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>li_txt<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
			<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>师老师<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>
			<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h4</span><span class="token punctuation">></span></span>高级讲师<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h4</span><span class="token punctuation">></span></span>
			<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>13年的项目开发和教育培训经验，精通Java EE的主流开发框架、Oracle和MySQL等关系型数据库。曾在中科院遥感应用研究所、慧点科技、达利本斯等公司担任软件开发工程师、项目总监，带团队做过边防部队、人寿集团、平安集团等多个企业的大型项目，之后在互联网公司知果科技担任开发经理，完成知果果网的核心产品开发。						<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>
			<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>所以,直接使用xpath来提取数据</p>
<p>我们先引用<code>Itcast/items.py</code>里面的<strong>ItcastItem</strong>类</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> Itcast<span class="token punctuation">.</span>items <span class="token keyword">import</span> ItcastItem
导包从项目的根目录下开始<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>然后将我们得到的数据封装到一个<strong>Itcastitem</strong>对象中，可以保存每个老师的属性:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> Itcast<span class="token punctuation">.</span>Itcast<span class="token punctuation">.</span>items <span class="token keyword">import</span> ItcastItem


<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Spider类</span>
    name <span class="token operator">=</span> <span class="token string">"itcast"</span>  <span class="token comment"># 爬虫名称</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.itcast.cn"</span><span class="token punctuation">]</span>  <span class="token comment"># 爬虫运行的域名</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">"http://www.itcast.cn/channel/teacher.shtml"</span>
    <span class="token punctuation">]</span>  <span class="token comment"># 起始url,爬虫程序启动的第一次请求目的url</span>

    <span class="token triple-quoted-string string">"""处理响应数据的方法"""</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"teacher.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>

        <span class="token comment"># 存放老师信息的集合</span>
        items <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> each <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
            <span class="token string">"//div[@class=' tea_txt']//ul//li//div[@class='li_txt']"</span>
        <span class="token punctuation">)</span><span class="token punctuation">:</span>	<span class="token comment"># each是一个结点,对节点使用xpath方法需要加'./'表示当前节点下</span>
            
            <span class="token comment"># 将我们得到的数据封装成一个ItcastItem对象</span>
            item <span class="token operator">=</span> ItcastItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># extract()方法返回的都是unicode字符串</span>
            name <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            title <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./h4/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            info <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># xpath返回的是包含一个元素的列表</span>
            item<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> name<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span> <span class="token operator">=</span> title<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"info"</span><span class="token punctuation">]</span> <span class="token operator">=</span> info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

            items<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>

        <span class="token comment"># 直接返回最后数据</span>
        <span class="token keyword">return</span> items
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们先不处理管道,后面会详细解释</p>
<h4 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h4><p>scrapy保存信息的最简单的方法主要有四种，-o输出指定格式的文件，命令如下</p>
<pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">如果spiders&#x2F;itcast.py中使用return 返回的是一个ItcastItem对象,会自动识别给piplines管道来处理数据
如果return的是ItcastItem对象的列表,可以使用以下命令来进行持久化存储

# json格式，默认为Unicode编码
scrapy crawl itcast -o teachers.json
# json lines格式，默认为Unicode编码
scrapy crawl itcast -o teachers.jsonl
# csv 逗号表达式，可用Exce1打开
scrapy crawl itcast -o teachers.csv
# xml格式
scrapy crawl itcast -o teachers.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>如果将代码改成下面形式，结果完全一样。请思考<strong>yield</strong>在这里的作用</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">from</span> Itcast<span class="token punctuation">.</span>items <span class="token keyword">import</span> ItcastItem


<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Spider类</span>
    name <span class="token operator">=</span> <span class="token string">"itcast"</span>  <span class="token comment"># 爬虫名称</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.itcast.cn"</span><span class="token punctuation">]</span>  <span class="token comment"># 爬虫运行的域名</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">"http://www.itcast.cn/channel/teacher.shtml"</span>
    <span class="token punctuation">]</span>  <span class="token comment"># 起始url,爬虫程序启动的第一次请求目的url</span>

    <span class="token triple-quoted-string string">"""处理响应数据的方法"""</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"teacher.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>

        <span class="token comment"># 存放老师信息的集合</span>
        <span class="token comment"># items = []</span>
        <span class="token keyword">for</span> each <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
            <span class="token string">"//div[@class=' tea_txt']//ul//li//div[@class='li_txt']/"</span>
        <span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 将我们得到的数据封装成一个ItcastItem对象</span>
            item <span class="token operator">=</span> ItcastItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># extract()方法返回的都是unicode字符串</span>
            name <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            title <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./h4/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            info <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># xpath返回的是包含一个元素的列表</span>
            item<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> name<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span> <span class="token operator">=</span> title<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"info"</span><span class="token punctuation">]</span> <span class="token operator">=</span> info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            
            <span class="token comment"># items.append(item)</span>
            
            <span class="token comment"># 将获取到的数据交给piplines,后继续回来执行</span>
            <span class="token keyword">yield</span> item

        <span class="token comment"># 直接返回最后数据</span>
        <span class="token comment"># return items</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p><strong>yield</strong>的作用是,执行到yield后,不会像return那样直接返回,函数结束,而是会在返回此次后继续到上次执行的位置继续执行,<strong>return每次调用返回的值都一样</strong></p>
</li>
<li><p>带有 <strong>yield</strong> 的函数不再是一个普通函数，而是一个生成器 generator，可用于迭代</p>
</li>
<li><p>yield 是一个类似 return 的关键字，迭代一次遇到 <strong>yield</strong> 时就返回 yield 后面(右边)的值。重点是:下一次迭代时，从上一次迭代遇到的yield后面的代码(下一行)开始执行</p>
</li>
<li><p>简要理解:yield就是 return 返回一个值，并且记住这个返回的位置，下次迭代就从这个位置后(下一行)开始</p>
</li>
</ul>
<h4 id="管道处理保存数据-piplines-py"><a href="#管道处理保存数据-piplines-py" class="headerlink" title="管道处理保存数据(piplines.py)"></a>管道处理保存数据(piplines.py)</h4><p>要先在settings.py中启用管道后,itcast.py爬取的数据才会经过piplines管道进行处理保存</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define your item pipelines here</span>
<span class="token comment">#</span>
<span class="token comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="token comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="token comment"># useful for handling different item types with a single interface</span>
<span class="token keyword">import</span> json


<span class="token keyword">class</span> <span class="token class-name">ItcastPipeline</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"itcast_piplines.json"</span><span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># item就是items.py返回的值</span>
        content <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>
            <span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span>  <span class="token comment"># 把字典转换成json格式,ensure_ascii表示不把中文字符串当做ascii码,而是unicode</span>
        self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 返回给引擎,告诉引擎处理完毕,给我下一个</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 整个爬虫程序关闭时做的事</span>
        self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
 	<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>需要在**<code>items.py</code>**中定义需要的属性</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ItcastItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Field()类似字典</span>
    info <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  
    <span class="token comment"># pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="Item-Pipline"><a href="#Item-Pipline" class="headerlink" title="Item Pipline"></a>Item Pipline</h2><p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline,这些Item Pipeline组件按定义的顺序处理Item.<br>每个Item Pipeline都是实现了简单方法的Python类，比如决定此Item是丢弃而存储。以下是item pipeline的一些典型应用:</p>
<ul>
<li>验证爬取的数据(检查item包含某些字段，比如说name字段)</li>
<li>查重(并丢弃)</li>
<li>将爬取结果保存到文件或者数据库中</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> something  <span class="token comment"># 确保这里的something是您实际想要导入的模块或包  </span>
  
<span class="token keyword">class</span> <span class="token class-name">SomethingPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token comment"># 可选实现，做参数初始化等  </span>
        <span class="token comment"># 这里可以添加初始化代码，例如连接数据库等  </span>
        <span class="token keyword">pass</span>  
    
	<span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token comment"># item(Item 对象) - 被爬取的item  </span>
        <span class="token comment"># spider(Spider 对象) - 爬取该item的spider  </span>
        <span class="token comment"># 这个方法必须实现，每个item pipeline组件都需要调用该方法  </span>
        <span class="token comment"># 方法必须返回一个 Item 对象，被丢弃的item将不会被之后的pipeline组件处理  </span>
        <span class="token comment"># 这里可以添加处理item的代码，比如清洗数据、保存数据到数据库等  </span>
        <span class="token keyword">return</span> item
    
    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token comment"># spider(Spider 对象) - 被开启的spider  </span>
        <span class="token comment"># 可选实现，当spider被开启时，这个方法被调用  </span>
        <span class="token comment"># 这里可以添加一些在spider启动时需要的初始化操作  </span>
        <span class="token keyword">pass</span>  
    
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token comment"># spider(Spider 对象) - 被关闭的spider  </span>
        <span class="token comment"># 可选实现，当spider被关闭时，这个方法被调用  </span>
        <span class="token comment"># 这里可以添加一些清理代码，比如关闭数据库连接等  </span>
        <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="Scrapy-Shell"><a href="#Scrapy-Shell" class="headerlink" title="Scrapy Shell"></a>Scrapy Shell</h2><p><strong>Scrapy终端</strong>是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试<strong>XPath</strong>或<strong>CSS</strong>表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据。</p>
<p>如果安装了IPython，Scrapy终端将使用 IPython(替代标准Python终端)。<strong>IPython</strong>终端与其他相比更为强大，提供智能的自动补全，高亮输出，及其他特性。(推荐安装IPython)</p>
<h3 id="启动scrapyshell"><a href="#启动scrapyshell" class="headerlink" title="启动scrapyshell"></a>启动scrapyshell</h3><p>进入项目的根目录，执行下列命令来启动shell</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">scrapy shell <span class="token string">"http://ww.itcast.cn/channel/teacher.shtml"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="/2024/08/04/scrapy-kuang-jia/image-20240803112644048.png" alt="image-20240803112644048"></p>
<p><strong>Scrapy Shell</strong>根据下载的页面会自动创建一些方便使用的对象，例如<code>Response</code>对象，以及<code>selector</code>对象(对HTML及XML内容)。</p>
<p>当shell载入后，将得到一个包含response数据的本地response变量，输入<code>response.body</code>将输出response的包体，输出response.headers 可以看到response的包头。</p>
<p>输入response.selector 时，将获取到一个response 初始化的类 Selector 的对象,此时可以通过使用 <code>response.selector.xpath()</code>或<code>response.selector.css()</code>来对 response 进行查询。</p>
<p>Scrapy也提供了一些快捷方式,例如 <code>response.xpath()</code>或<code> response.css()</code>同样可以生效(如之前的案例)。</p>
<h3 id="Selectors选择器"><a href="#Selectors选择器" class="headerlink" title="Selectors选择器"></a>Selectors选择器</h3><p><strong>Scrapy Selectors</strong> 内置 <strong>XPath</strong> 和 <strong>Css Selector</strong> 表达式机制</p>
<p>Selector有四个基本的方法，最常用的还是xpath</p>
<ul>
<li><code>xpath()</code>:传入xpath表达式，返回该表达式所对应的所有节点的selector list列表</li>
<li><code>extract()</code>:序列化该节点为Unicode字符串并回list</li>
<li><code>css()</code>:传入CSS表达式，返回该表达式所对应的所有节点的selector list列表,语法同 BeautifulSoup4。</li>
<li><code>re()</code>:根据传入的正则表达式对数据进行提取，返回Unicode字符串list列表</li>
</ul>
<pre class="line-numbers language-txt" data-language="txt"><code class="language-txt"># 定位页面上的所有链接  
//a  
  
# 定位具有特定类名的元素，例如所有类名为"my-class"的&lt;div>元素  
//div[@class='my-class']  
  
# 如果类名有多个值，定位包含特定类名的元素  
//div[contains(concat(' ', normalize-space(@class), ' '), ' my-class ')]  
  
# 定位包含特定文本的元素，例如所有包含"点击这里"文本的&lt;a>元素  
//a[contains(text(), '点击这里')]  
  
# 定位具有特定属性值的元素，例如所有href属性中包含"example.com"的&lt;a>元素  
//a[contains(@href, 'example.com')]  
  
# 定位某个特定元素下的所有直接子元素，例如&lt;div id="container">下的所有&lt;p>元素  
//div[@id='container']/p  
  
# 定位具有特定id的元素，例如id为"unique-id"的&lt;div>元素  
//div[@id='unique-id']<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Spider"><a href="#Spider" class="headerlink" title="Spider"></a>Spider</h2><p><strong>Spider</strong>类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 </p>
<p>换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p><code>class scrapy.spider</code> 是最基本的类，所有编写的爬虫必须继承这个类。</p>
<p>主要用到的函数及调用顺序为:</p>
<ul>
<li><code>init_()</code>: 初始化爬虫名字和start_urls列表</li>
<li><code>start_requests()</code>: 调用<code>make_requests_from_url()</code>生成Requests对象交给Scrapy下载并返response </li>
<li><code>parse()</code>: 解析response,并返回 Item 或 Requests (需指定回调函数)。Item传给<strong>item pipline</strong>持久化 ，而Requests交由Scrapy下载，并由指定的回调函数处理(默认parse()，一直进行循环，直到处理完所有的数据为止。)</li>
</ul>
<h3 id="源码参考"><a href="#源码参考" class="headerlink" title="源码参考"></a>源码参考</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 所有爬虫的基类，用户定义的爬虫必须从这个类继承</span>
<span class="token keyword">class</span> <span class="token class-name">Spider</span><span class="token punctuation">(</span>object_ref<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Base class for scrapy spiders. All spiders must inherit from this class."""</span>

    name<span class="token punctuation">:</span> <span class="token builtin">str</span>
    custom_settings<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
    
   <span class="token comment"># 定义spider名字的字符串(string)。spider的名字定义了scrapy如何定位(并初始化)spider，所以其必须是唯一的</span>
   <span class="token comment"># name是spider最重要的属性，而且是必须的。</span>
	<span class="token comment"># 一般做法是以该网站(domain)(加或不加后缀)来命名spider。例如，如果spider爬取mywebsite.com，该spider名为mywebsite</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> name <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>name <span class="token operator">=</span> name
        <span class="token comment"># 如果爬虫没有名字，中断后续操作则报错</span>
        <span class="token keyword">elif</span> <span class="token keyword">not</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">type</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__name__<span class="token punctuation">&#125;</span></span><span class="token string"> must have a name"</span></span><span class="token punctuation">)</span>
            
        <span class="token comment"># python 对象或类型通过内置成员_dict 来存储成员信息</span>
        self<span class="token punctuation">.</span>__dict__<span class="token punctuation">.</span>update<span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span>
        
        <span class="token comment"># URL列表。当没有指定的URL时，spider将从该列表中开始进行爬取。 因此，第一个被获取到的页面的URL将是该列表的内容</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">"start_urls"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">logger</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> logging<span class="token punctuation">.</span>LoggerAdapter<span class="token punctuation">:</span>
        logger <span class="token operator">=</span> logging<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span>self<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logging<span class="token punctuation">.</span>LoggerAdapter<span class="token punctuation">(</span>logger<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">"spider"</span><span class="token punctuation">:</span> self<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

    <span class="token comment"># 打印scrapy执行后的1og信息</span>
    <span class="token keyword">def</span> <span class="token function">log</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">:</span> Any<span class="token punctuation">,</span> level<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> logging<span class="token punctuation">.</span>DEBUG<span class="token punctuation">,</span> <span class="token operator">**</span>kw<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Log the given message at the given log level

        This helper wraps a log call to the logger within the spider, but you
        can use it directly (e.g. Spider.logger.info('msg')) or use any other
        Python logger too.
        """</span>
        self<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>log<span class="token punctuation">(</span>level<span class="token punctuation">,</span> message<span class="token punctuation">,</span> <span class="token operator">**</span>kw<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">:</span> Crawler<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">:</span> Any<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Self<span class="token punctuation">:</span>
        spider <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        spider<span class="token punctuation">.</span>_set_crawler<span class="token punctuation">(</span>crawler<span class="token punctuation">)</span>
        <span class="token keyword">return</span> spider

    <span class="token comment"># 判断对象object的属性是否存在，不存在做断言处理</span>
    <span class="token keyword">def</span> <span class="token function">_set_crawler</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> crawler<span class="token punctuation">:</span> Crawler<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>crawler <span class="token operator">=</span> crawler
        self<span class="token punctuation">.</span>settings <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings
        crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>close<span class="token punctuation">,</span> signals<span class="token punctuation">.</span>spider_closed<span class="token punctuation">)</span>

        
    <span class="token comment"># 该方法将读取start_urls内的地址，并为每一个地址生成一个Request对象，交给Scrapy下载并返回Response#该方法仅调用一次</span>
    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Iterable<span class="token punctuation">[</span>Request<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>start_urls <span class="token keyword">and</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">"start_url"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> AttributeError<span class="token punctuation">(</span>
                <span class="token string">"Crawling could not start: 'start_urls' not found "</span>
                <span class="token string">"or empty (but found 'start_url' attribute instead, "</span>
                <span class="token string">"did you miss an 's'?)"</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> self<span class="token punctuation">.</span>make_requests_from_url<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
            
    <span class="token keyword">def</span>  <span class="token function">make_requests_from_url</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#start_requests()中调用，实际生成Request的函数。</span>
        <span class="token comment">#Request对象默认的回调函数为parse()，提交的方式为get</span>
       	<span class="token keyword">return</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> dont_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">:</span> Response<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Any<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>response<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

    
    <span class="token comment"># 默认的Request对象回调函数，处理返回的response.</span>
    <span class="token comment"># 生成Item或者Request对象。用户必须实现这个类</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">:</span> Response<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Any<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span>
            <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>self<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__<span class="token punctuation">&#125;</span></span><span class="token string">.parse callback is not defined"</span></span>
        <span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">update_settings</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> settings<span class="token punctuation">:</span> BaseSettings<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        settings<span class="token punctuation">.</span>setdict<span class="token punctuation">(</span>cls<span class="token punctuation">.</span>custom_settings <span class="token keyword">or</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> priority<span class="token operator">=</span><span class="token string">"spider"</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">handles_request</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> request<span class="token punctuation">:</span> Request<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">bool</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> url_is_from_spider<span class="token punctuation">(</span>request<span class="token punctuation">.</span>url<span class="token punctuation">,</span> cls<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">close</span><span class="token punctuation">(</span>spider<span class="token punctuation">:</span> Spider<span class="token punctuation">,</span> reason<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Union<span class="token punctuation">[</span>Deferred<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        closed <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>spider<span class="token punctuation">,</span> <span class="token string">"closed"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">callable</span><span class="token punctuation">(</span>closed<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> cast<span class="token punctuation">(</span>Union<span class="token punctuation">[</span>Deferred<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">,</span> closed<span class="token punctuation">(</span>reason<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"&lt;</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">type</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__name__<span class="token punctuation">&#125;</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">&#123;</span>self<span class="token punctuation">.</span>name<span class="token conversion-option punctuation">!r</span><span class="token punctuation">&#125;</span></span><span class="token string"> at 0x</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">id</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0x</span><span class="token punctuation">&#125;</span></span><span class="token string">>"</span></span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/jira/p/16574364.html">Python @property装饰器详解 - 贾志文 - 博客园 (cnblogs.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhh763984017/article/details/120072425">【Python】一文弄懂python装饰器（附源码例子）_python 装饰器-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/python-func-decorators.html">Python 函数装饰器 | 菜鸟教程 (runoob.com)</a></p>
<ul>
<li><p><strong>name</strong>	定义spider名字的字符串。</p>
<p>  例如，如果spider爬取 mywebsite.com，该spider通常会被命名为 mywebsite</p>
</li>
<li><p><strong>allowed domains</strong></p>
<p>  包含了spider允许爬取的域名(domain)的列表，可选。</p>
</li>
<li><p><strong>start urls</strong></p>
<p>  初始URL元组&#x2F;列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。</p>
</li>
<li><p><strong>start requests(self)</strong></p>
<p>该方法必须返回一个可迭代对象(iterable)。该对象包含了spider用于爬取(默认实现是使用start urls 的</p>
<p>url)的第一个Request.当spider启动爬取并且未指定start urls时，该方法被调用。</p>
</li>
<li><p><strong>parse(self, response)</strong></p>
<p>  当请求url返回网页没有指定回调函数时，默认的Request对象回调函数。用来处理网页返回的response，以及生成Item或者Request对象。</p>
</li>
<li><p><strong>log(self,messagel.level, component])</strong></p>
<p>  使用 scrapy.log.msg()方法记录(log)message。更多数据请参见 logging</p>
</li>
</ul>
<h3 id="尝试腾讯招聘案例-普通版"><a href="#尝试腾讯招聘案例-普通版" class="headerlink" title="尝试腾讯招聘案例(普通版)"></a>尝试腾讯招聘案例(普通版)</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hwwaizs/article/details/120392605">python爬虫（二十二）scrapy案例–爬取腾讯招聘数据_爬取腾讯社会招聘“数据分析”岗位的所有招聘信息-CSDN博客</a></p>
<p>我们用腾讯社招的网站<a target="_blank" rel="noopener" href="https://careers.tencent.com/search.html?index=1">搜索 | 腾讯招聘 (tencent.com)</a>举例:</p>
<p>(<a target="_blank" rel="noopener" href="http://hr.tencent.com/position.php?&start=0#a%E4%B8%AD#a%E8%A1%A8%E7%A4%BA%E9%94%9A%E7%82%B9,%E5%AE%9A%E4%BD%8D%E5%88%B0%E9%A1%B5%E9%9D%A2%E7%9A%84%E5%93%AA%E4%B8%AA%E4%BD%8D%E7%BD%AE">http://hr.tencent.com/position.php?&amp;start=0#a中#a表示锚点,定位到页面的哪个位置</a>)</p>
<h4 id="首先分析要爬取的数据有哪些"><a href="#首先分析要爬取的数据有哪些" class="headerlink" title="首先分析要爬取的数据有哪些"></a>首先分析要爬取的数据有哪些</h4><img src="/2024/08/04/scrapy-kuang-jia/分析要爬取的数据.png" alt="image-20240803133142140">

<p>根节点的xpath路径为<code>//div[@class=&#39;recruit-list&#39;]/a</code></p>
<p><strong>初步确定要爬取的信息</strong></p>
<p>职位名positionName: <code>//div[@class=&#39;recruit-list&#39;]/a/div/span[1]</code></p>
<p>职位类别positionType: <code>//div[@class=&#39;recruit-list&#39;]/a/p/span[3]</code></p>
<p>职位要求positionRequire:<code>//div[@class=&#39;recruit-list&#39;]/a/p/span[5]</code></p>
<p>工作地点workLocation: <code>//div[@class=&#39;recruit-list&#39;]/a/div/span[2]</code></p>
<p>详细介绍positionInfo: <code>//div[@class=&#39;recruit-list&#39;]/a/p[@class=&#39;recruit-text&#39;]</code></p>
<p>最后更新时间updateTime:<code>//div[@class=&#39;recruit-list&#39;]/a/p/span[7]</code></p>
<h4 id="然后创建爬虫项目和程序"><a href="#然后创建爬虫项目和程序" class="headerlink" title="然后创建爬虫项目和程序"></a>然后创建爬虫项目和程序</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">scrapy startproject Tencent
 <span class="token builtin class-name">cd</span> .<span class="token punctuation">\</span>Tencent<span class="token punctuation">\</span>
scrapy genspider  tencent <span class="token string">"tencent.com"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h4 id="items-py"><a href="#items-py" class="headerlink" title="items.py"></a>items.py</h4><p>定义要采集的数据模型</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define here the models for your scraped items</span>
<span class="token comment">#</span>
<span class="token comment"># See documentation in:</span>
<span class="token comment"># https://docs.scrapy.org/en/latest/topics/items.html</span>

<span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">TencentItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    <span class="token comment"># 职位名</span>
    positionName <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 职位类别</span>
    positionType <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 职位要求</span>
    positionRequire <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 工作地点</span>
    workLocation <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 详细介绍</span>
    positionInfo <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 最后更新时间</span>
    updateTime <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="tencent-py"><a href="#tencent-py" class="headerlink" title="tencent.py"></a>tencent.py</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> Tencent<span class="token punctuation">.</span>items <span class="token keyword">import</span> TencentItem


<span class="token keyword">class</span> <span class="token class-name">TencentSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"tencent"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"tencent.com"</span><span class="token punctuation">]</span>
    baseUrl <span class="token operator">=</span> <span class="token string">"http://hr.tencent.com/search.html?index="</span>
    index <span class="token operator">=</span> <span class="token number">1</span>
    start_url <span class="token operator">=</span> <span class="token punctuation">[</span>baseUrl <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>

        node_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='recruit-list']/a"</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> node <span class="token keyword">in</span> node_list<span class="token punctuation">:</span>
            item <span class="token operator">=</span> TencentItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 提取每个职位的信息</span>
            item<span class="token punctuation">[</span><span class="token string">"positionName"</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./div/span[1]/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"positionType"</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
                <span class="token string">"//div[@class='recruit-list']/a/p/span[3]/text()"</span>
            <span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"positionRequire"</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
                <span class="token string">"//div[@class='recruit-list']/a/p/span[5]/text()"</span>
            <span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"workLocation"</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./div/span[2]/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"positionInfo"</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
                <span class="token string">"//div[@class='recruit-list']/a/p[@class='recruit-text']/text()"</span>
            <span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"updateTime"</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
                <span class="token string">"//div[@class='recruit-list']/a/p/span[7]/text()"</span>
            <span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

            <span class="token keyword">yield</span> item

         <span class="token comment"># 此次硬编码,不是最佳方案,可在每一页中提取下一页url</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>index <span class="token operator">&lt;</span> <span class="token number">282</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>index <span class="token operator">+=</span> <span class="token number">10</span>
            url <span class="token operator">=</span> self<span class="token punctuation">.</span>baseUrl <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>index<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>

    <span class="token comment"># def parse_next(self,response):</span>
    <span class="token comment">#     pass</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><code>start_url = [baseUrl + str(index)]</code>:拼接请求网址</li>
<li><code>yield scrapy.Request(url=url, callback=self.parse)</code>: 对新网址发送请求,callback函数可自己定义</li>
<li>yield会把item&#x2F;Request返回给引擎,引擎判断是交给管道保存还是继续进入请求队列</li>
</ul>
<h4 id="piplines-py"><a href="#piplines-py" class="headerlink" title="piplines.py"></a>piplines.py</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define your item pipelines here</span>
<span class="token comment">#</span>
<span class="token comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="token comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="token comment"># useful for handling different item types with a single interface</span>
<span class="token keyword">import</span> json
<span class="token keyword">from</span> itemadapter <span class="token keyword">import</span> ItemAdapter


<span class="token keyword">class</span> <span class="token class-name">TencentPipeline</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"data.json"</span><span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span> <span class="token operator">+</span> item<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">",\n"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h3 id="腾讯招聘-抓包"><a href="#腾讯招聘-抓包" class="headerlink" title="腾讯招聘(抓包)"></a>腾讯招聘(抓包)</h3><h4 id="什么是抓包"><a href="#什么是抓包" class="headerlink" title="什么是抓包"></a>什么是抓包</h4><p>在网络爬虫的上下文中，抓包技术可以被用来分析和优化爬虫的性能。具体来说，爬虫开发者可以使用抓包工具（如</p>
<p>Wireshark、tcpdump等）来捕获爬虫程序与服务器之间的通信数据包。通过对这些数据包的分析，开发者可以了解爬虫</p>
<p>请求的发送情况、服务器的响应情况，以及请求和响应中携带的具体数据内容。</p>
<h4 id="分析请求"><a href="#分析请求" class="headerlink" title="分析请求"></a>分析请求</h4><p>打开腾讯招聘页面,右键源代码,随便搜索一个网页中的职位名称,结果为空,说明,职位信息是动态响应到界面中的;</p>
<p>此时,就要到网络中去抓包,按F11打开调试工具,点到网络项,XHR,然后刷新界面,逐个检查发现<code>Query</code>开头的请求返回的响应数据(预览)中有我们想要的数据.</p>
<p>复制请求url,在另一窗口打开,不断删除参数,最后发现,只需要简单的<code>https://careers.tencent.com/tencentcareer/api/post/Query?pageIndex=281&amp;pageSize=10</code>就能访问到数据,再将相隔两页对比数据,发现<strong>pageIndex的值</strong>就是当前页面的索引,<strong>pageSize固定为10</strong>(每页展示的招聘信息总数)</p>
<p><img src="/2024/08/04/scrapy-kuang-jia/%E6%8A%93%E5%8C%85%E4%B9%8Bxhr.png" alt="image-20240804094111942"></p>
<p>所以,我们试探性的将pageIndex改为1,果然发现获取到了第一页的招聘信息</p>
<p><img src="/2024/08/04/scrapy-kuang-jia/%E7%AE%80%E5%8C%96url.png" alt="image-20240804094920088"></p>
<h4 id="爬取数据"><a href="#爬取数据" class="headerlink" title="爬取数据"></a>爬取数据</h4><p>把上面请求的响应数据放到json解析器中去,解析想要的数据所处的格式</p>
<p><img src="/2024/08/04/scrapy-kuang-jia/json%E6%A0%BC%E5%BC%8F%E7%9A%84%E5%93%8D%E5%BA%94.png" alt="image-20240804095531422"></p>
<h4 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h4><p>在<code>spiders/tencent.py</code>中</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> json
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> Tencent<span class="token punctuation">.</span>items <span class="token keyword">import</span> TencentItem


<span class="token keyword">class</span> <span class="token class-name">TencentSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"tencent"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"tencent.com"</span><span class="token punctuation">]</span>
    index <span class="token operator">=</span> <span class="token number">1</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string-interpolation"><span class="token string">f"http://careers.tencent.com/tencentcareer/api/post/Query?pageIndex=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>index<span class="token punctuation">&#125;</span></span><span class="token string">&amp;pageSize=10"</span></span>
    <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================================"</span><span class="token punctuation">)</span>	<span class="token comment"># 输出一行,让你更容易看到输出信息,后面写完项目可以注释掉</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>	<span class="token comment"># 返回json数据</span>
        data_dict <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>	<span class="token comment"># 把json数据变成python字典类型</span>
        RecruitPostName <span class="token operator">=</span> data_dict<span class="token punctuation">[</span><span class="token string">"Data"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"Posts"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"RecruitPostName"</span><span class="token punctuation">]</span>	<span class="token comment"># 解嵌套</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span>RecruitPostName<span class="token punctuation">)</span>	
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================================"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>经过一系列操作,最后成功获得想要的第一个职位信息</p>
<p><img src="/2024/08/04/scrapy-kuang-jia/%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%81%8C%E4%BD%8D%E4%BF%A1%E6%81%AF.png" alt="image-20240804102136386"></p>
<p>最终代码为</p>
<h5 id="tencent-py-1"><a href="#tencent-py-1" class="headerlink" title="tencent.py"></a>tencent.py</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> json
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> Tencent<span class="token punctuation">.</span>items <span class="token keyword">import</span> TencentItem


<span class="token keyword">class</span> <span class="token class-name">TencentSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"tencent"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"tencent.com"</span><span class="token punctuation">]</span>
    index <span class="token operator">=</span> <span class="token number">1</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string-interpolation"><span class="token string">f"http://careers.tencent.com/tencentcareer/api/post/Query?pageIndex=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>index<span class="token punctuation">&#125;</span></span><span class="token string">&amp;pageSize=10"</span></span>
    <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
        data_dict <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>
        datas <span class="token operator">=</span> data_dict<span class="token punctuation">[</span><span class="token string">"Data"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"Posts"</span><span class="token punctuation">]</span>  <span class="token comment"># 返回一个数组</span>

        <span class="token keyword">for</span> data <span class="token keyword">in</span> datas<span class="token punctuation">:</span>
            item <span class="token operator">=</span> TencentItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">"positionName"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"RecruitPostName"</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"workLocation"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"LocationName"</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"positionType"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"CategoryName"</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"positionInfo"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"Responsibility"</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"PostURL"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"PostURL"</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">"updateTime"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"LastUpdateTime"</span><span class="token punctuation">]</span>

            <span class="token keyword">yield</span> item

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>index <span class="token operator">&lt;</span> <span class="token number">282</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>index <span class="token operator">+=</span> <span class="token number">1</span>
            url <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"http://careers.tencent.com/tencentcareer/api/post/Query?pageIndex=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>self<span class="token punctuation">.</span>index<span class="token punctuation">&#125;</span></span><span class="token string">&amp;pageSize=10"</span></span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>


<span class="token comment"># def parse_next(self,response):</span>
<span class="token comment">#     pass</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="items-py-1"><a href="#items-py-1" class="headerlink" title="items.py"></a>items.py</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define here the models for your scraped items</span>
<span class="token comment">#</span>
<span class="token comment"># See documentation in:</span>
<span class="token comment"># https://docs.scrapy.org/en/latest/topics/items.html</span>

<span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">TencentItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    <span class="token comment"># 职位名</span>
    positionName <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 职位类别</span>
    positionType <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 职位详情url</span>
    PostURL <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 工作地点</span>
    workLocation <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 详细介绍</span>
    positionInfo <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 最后更新时间</span>
    updateTime <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="piplines-py-1"><a href="#piplines-py-1" class="headerlink" title="piplines.py"></a>piplines.py</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define your item pipelines here</span>
<span class="token comment">#</span>
<span class="token comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="token comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="token comment"># useful for handling different item types with a single interface</span>
<span class="token keyword">import</span> json
<span class="token keyword">from</span> itemadapter <span class="token keyword">import</span> ItemAdapter


<span class="token keyword">class</span> <span class="token class-name">TencentPipeline</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"data.json"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">",\n"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"成功写入</span><span class="token interpolation"><span class="token punctuation">&#123;</span>x<span class="token punctuation">&#125;</span></span><span class="token string">个字符"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

        <span class="token comment"># def close_spider(self, spider):</span>
        self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="运行结果展示"><a href="#运行结果展示" class="headerlink" title="运行结果展示"></a>运行结果展示</h5><p><img src="/2024/08/04/scrapy-kuang-jia/%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA.png" alt="image-20240804103841776"></p>
<h2 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h2><h3 id="独门秘笈"><a href="#独门秘笈" class="headerlink" title="独门秘笈"></a>独门秘笈</h3><ol>
<li><p>继承自scrapy.Spider</p>
</li>
<li><p>独门秘笈<br> CrawlSpider可以定义规则，再解析html内容的时候，可以根据链接规则提取出指定的链接，然后再向这些链接发</p>
<p> 送请求所以，如果有需要跟进链接的需求，意思就是爬取了网页之后，需要提取链接再次爬取，使用<strong>CrawlSpider</strong></p>
<p> 是非常合适的</p>
</li>
<li><p>提取链接<br> 链接提取器，在这里就可以写规则提取指定链接    </p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python">scrapy<span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>LinkExtractor<span class="token punctuation">(</span> 
    <span class="token comment"># 正则表达式  提取符合正则的链接</span>
    allow <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    <span class="token comment"># (不用)正则表达式  不提取符合正则的链接</span>
    deny <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     
    <span class="token comment">#（不用）允许的域名  </span>
    allow_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  
    <span class="token comment">#（不用）不允许的域名   </span>
    deny_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token comment"># xpath，提取符合xpath规则的链接</span>
    restrict_xpaths <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      
    <span class="token comment"># 提取符合选择器规则的链接</span>
    restrict_css <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>         
   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p>模拟使用</p>
<ul>
<li>正则用法:<code>links1 = LinkExtractor(allow=r&#39;list 23 \d+\.html&#39;)</code></li>
<li>xpath用法:<code>links2 = LinkExtractor(restrict xpaths=r&#39;//div[@class=&quot;x&quot;]&#39;)</code></li>
<li>css用法:<code>links3 = LinkExtractor(restrict css=&#39;.x&#39;)</code></li>
</ul>
</li>
<li><p>提取连接<br> <code>link.extract_links(response)</code></p>
</li>
<li><p>注意事项<br> 【注1】callback只能写函数名字符串，<strong>callback&#x3D;’parse item’</strong><br> 【注2】在基本的spider中，如果重新发送请求，那里的callback写的是callback&#x3D;self.parse_item</p>
</li>
<li><p>follow&#x3D;true 是否跟进 就是按照提取连接规则进行提取</p>
</li>
</ol>
<p><img src="/2024/08/04/scrapy-kuang-jia/follow%E8%A7%84%E5%88%99.png" alt="image-20240804110723859"></p>
<h2 id="CrawlSpider案例"><a href="#CrawlSpider案例" class="headerlink" title="CrawlSpider案例"></a>CrawlSpider案例</h2><h3 id="read-py"><a href="#read-py" class="headerlink" title="read.py"></a><code>read.py</code></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule
<span class="token keyword">from</span> scrapy_dushuwang<span class="token punctuation">.</span>items <span class="token keyword">import</span> ScrapyDushuwangItem


<span class="token keyword">class</span> <span class="token class-name">ReadSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"read"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.dushu.com"</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"https://www.dushu.com/book/1107.html"</span><span class="token punctuation">]</span>
    <span class="token comment"># 正则表达式r"/book/\d+\.html"</span>
    rules <span class="token operator">=</span> <span class="token punctuation">(</span>Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r"/book/\d+\.html"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  callback<span class="token operator">=</span><span class="token string">"parse_item"</span><span class="token punctuation">,</span>
                  follow<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># follow是要不要继续提取</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================"</span><span class="token punctuation">)</span>
        <span class="token comment"># 第一张图片没有懒加载,所以要加入图片源</span>
        <span class="token comment"># img_list[0] = "https://a.dushu.com/img/n142.png"</span>
        img_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="bookslist"]/ul//img/@data-original'</span><span class="token punctuation">)</span>
        name_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="bookslist"]/ul//a/@title'</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> item <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>img_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> item <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                name <span class="token operator">=</span> name_list<span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                src <span class="token operator">=</span> <span class="token string">"https://a.dushu.com/img/n142.png"</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                name <span class="token operator">=</span> name_list<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
                src <span class="token operator">=</span> img_list<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            book <span class="token operator">=</span> ScrapyDushuwangItem<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">,</span> src<span class="token operator">=</span>src<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> book
<span class="token comment"># item = &#123;&#125; # 建议使用在items文件中定义数据结构</span>
<span class="token comment"># # item["domain_id"] = response.xpath('//input[@id="sid"]/@value').get()</span>
<span class="token comment"># # item["name"] = response.xpath('//div[@id="name"]').get()</span>
<span class="token comment"># # item["description"] = response.xpath('//div[@id="description"]').get()</span>
<span class="token comment"># return item</span>

<span class="token comment"># 创建新的请求并重新执行提取</span>
<span class="token comment"># next_page = response.xpath('//a[contains(text(), "下一页")]/@href').get()  # 获取下一页的链接</span>
<span class="token comment"># if next_page:</span>
<span class="token comment"># yield scrapy.Request(next_page, callback=self.parse_item)  # 重新执行提取，回调函数为 self.parse_item</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="items-py-2"><a href="#items-py-2" class="headerlink" title="items.py"></a><code>items.py</code></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define here the models for your scraped items</span>
<span class="token comment">#</span>
<span class="token comment"># See documentation in:</span>
<span class="token comment"># https://docs.scrapy.org/en/latest/topics/items.html</span>

<span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">ScrapyDushuwangItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    src <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="piplines-py-2"><a href="#piplines-py-2" class="headerlink" title="piplines.py"></a><code>piplines.py</code></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Define your item pipelines here</span>
<span class="token comment">#</span>
<span class="token comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="token comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="token comment"># useful for handling different item types with a single interface</span>


<span class="token keyword">class</span> <span class="token class-name">ScrapyDushuwangPipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'book.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">import</span> pymysql
<span class="token comment"># 加载settings文件</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>project <span class="token keyword">import</span> get_project_settings


<span class="token keyword">class</span> <span class="token class-name">MySqlPipline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        settings <span class="token operator">=</span> get_project_settings<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>host <span class="token operator">=</span> settings<span class="token punctuation">[</span><span class="token string">'DB_HOST'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>port <span class="token operator">=</span> settings<span class="token punctuation">[</span><span class="token string">'DB_PORT'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>user <span class="token operator">=</span> settings<span class="token punctuation">[</span><span class="token string">'DB_USER'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>password <span class="token operator">=</span> settings<span class="token punctuation">[</span><span class="token string">'DB_PASSWORD'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>name <span class="token operator">=</span> settings<span class="token punctuation">[</span><span class="token string">'DB_NAME'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>charset <span class="token operator">=</span> settings<span class="token punctuation">[</span><span class="token string">'DB_CHARSET'</span><span class="token punctuation">]</span>

        self<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">connect</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>conn <span class="token operator">=</span> pymysql<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>
            host<span class="token operator">=</span>self<span class="token punctuation">.</span>host<span class="token punctuation">,</span>
            port<span class="token operator">=</span>self<span class="token punctuation">.</span>port<span class="token punctuation">,</span>
            user<span class="token operator">=</span>self<span class="token punctuation">.</span>user<span class="token punctuation">,</span>
            password<span class="token operator">=</span>self<span class="token punctuation">.</span>password<span class="token punctuation">,</span>
            db<span class="token operator">=</span>self<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
            charset<span class="token operator">=</span>self<span class="token punctuation">.</span>charset
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>cursor <span class="token operator">=</span> self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sql <span class="token operator">=</span> <span class="token string">'insert into book(name,src) values("&#123;&#125;","&#123;&#125;")'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 执行sql语句</span>
        self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>
        <span class="token comment"># 提交</span>
        self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a><code>settings.py</code></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Scrapy settings for scrapy_dushuwang project</span>
<span class="token comment">#</span>
<span class="token comment"># For simplicity, this file contains only settings considered important or</span>
<span class="token comment"># commonly used. You can find more settings consulting the documentation:</span>
<span class="token comment">#</span>
<span class="token comment">#     https://docs.scrapy.org/en/latest/topics/settings.html</span>
<span class="token comment">#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span class="token comment">#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span>

BOT_NAME <span class="token operator">=</span> <span class="token string">"scrapy_dushuwang"</span>

SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"scrapy_dushuwang.spiders"</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">"scrapy_dushuwang.spiders"</span>

<span class="token comment"># 连接mysql参数</span>
DB_HOST <span class="token operator">=</span> <span class="token string">'127.0.0.1'</span>
<span class="token comment"># DB_HOST = 'localhost'</span>
DB_PORT <span class="token operator">=</span> <span class="token number">3306</span>
DB_USER <span class="token operator">=</span> <span class="token string">'root'</span>
DB_PASSWORD <span class="token operator">=</span> <span class="token string">'Xubin159753123'</span>
DB_NAME <span class="token operator">=</span> <span class="token string">"spider01"</span>
<span class="token comment"># 注意utf-8的-不允许写</span>
DB_CHARSET <span class="token operator">=</span> <span class="token string">'utf8'</span>

<span class="token comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="token comment"># USER_AGENT = "scrapy_dushuwang (+http://www.yourdomain.com)"</span>

<span class="token comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">True</span>

<span class="token comment"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span>
<span class="token comment"># CONCURRENT_REQUESTS = 32</span>

<span class="token comment"># Configure a delay for requests for the same website (default: 0)</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay</span>
<span class="token comment"># See also autothrottle settings and docs</span>
<span class="token comment"># DOWNLOAD_DELAY = 3</span>
<span class="token comment"># The download delay setting will honor only one of:</span>
<span class="token comment"># CONCURRENT_REQUESTS_PER_DOMAIN = 16</span>
<span class="token comment"># CONCURRENT_REQUESTS_PER_IP = 16</span>

<span class="token comment"># Disable cookies (enabled by default)</span>
<span class="token comment"># COOKIES_ENABLED = False</span>

<span class="token comment"># Disable Telnet Console (enabled by default)</span>
<span class="token comment"># TELNETCONSOLE_ENABLED = False</span>

<span class="token comment"># Override the default request headers:</span>
<span class="token comment"># DEFAULT_REQUEST_HEADERS = &#123;</span>
<span class="token comment">#    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",</span>
<span class="token comment">#    "Accept-Language": "en",</span>
<span class="token comment"># &#125;</span>

<span class="token comment"># Enable or disable spider middlewares</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span>
<span class="token comment"># SPIDER_MIDDLEWARES = &#123;</span>
<span class="token comment">#    "scrapy_dushuwang.middlewares.ScrapyDushuwangSpiderMiddleware": 543,</span>
<span class="token comment"># &#125;</span>

<span class="token comment"># Enable or disable downloader middlewares</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span class="token comment"># DOWNLOADER_MIDDLEWARES = &#123;</span>
<span class="token comment">#    "scrapy_dushuwang.middlewares.ScrapyDushuwangDownloaderMiddleware": 543,</span>
<span class="token comment"># &#125;</span>

<span class="token comment"># Enable or disable extensions</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/extensions.html</span>
<span class="token comment"># EXTENSIONS = &#123;</span>
<span class="token comment">#    "scrapy.extensions.telnet.TelnetConsole": None,</span>
<span class="token comment"># &#125;</span>

<span class="token comment"># Configure item pipelines</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">"scrapy_dushuwang.pipelines.ScrapyDushuwangPipeline"</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
    <span class="token comment"># MySqlPipline:"</span>
    <span class="token string">"scrapy_dushuwang.pipelines.MySqlPipline"</span><span class="token punctuation">:</span> <span class="token number">301</span>
<span class="token punctuation">&#125;</span>

<span class="token comment"># Enable and configure the AutoThrottle extension (disabled by default)</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/autothrottle.html</span>
<span class="token comment"># AUTOTHROTTLE_ENABLED = True</span>
<span class="token comment"># The initial download delay</span>
<span class="token comment"># AUTOTHROTTLE_START_DELAY = 5</span>
<span class="token comment"># The maximum download delay to be set in case of high latencies</span>
<span class="token comment"># AUTOTHROTTLE_MAX_DELAY = 60</span>
<span class="token comment"># The average number of requests Scrapy should be sending in parallel to</span>
<span class="token comment"># each remote server</span>
<span class="token comment"># AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span>
<span class="token comment"># Enable showing throttling stats for every response received:</span>
<span class="token comment"># AUTOTHROTTLE_DEBUG = False</span>

<span class="token comment"># Enable and configure HTTP caching (disabled by default)</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span>
<span class="token comment"># HTTPCACHE_ENABLED = True</span>
<span class="token comment"># HTTPCACHE_EXPIRATION_SECS = 0</span>
<span class="token comment"># HTTPCACHE_DIR = "httpcache"</span>
<span class="token comment"># HTTPCACHE_IGNORE_HTTP_CODES = []</span>
<span class="token comment"># HTTPCACHE_STORAGE = "scrapy.extensions.httpcache.FilesystemCacheStorage"</span>

<span class="token comment"># Set settings whose default value is deprecated to a future-proof value</span>
REQUEST_FINGERPRINTER_IMPLEMENTATION <span class="token operator">=</span> <span class="token string">"2.7"</span>
TWISTED_REACTOR <span class="token operator">=</span> <span class="token string">"twisted.internet.asyncioreactor.AsyncioSelectorReactor"</span>
FEED_EXPORT_ENCODING <span class="token operator">=</span> <span class="token string">"utf-8"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="日志信息和日志等级"><a href="#日志信息和日志等级" class="headerlink" title="日志信息和日志等级"></a>日志信息和日志等级</h2><ul>
<li><p>日志级别:</p>
<ul>
<li><p><strong>CRITICAL</strong>: 严重错误</p>
</li>
<li><p><strong>ERROR</strong>: 一般错误</p>
</li>
<li><p><strong>WARNING</strong>: 警告</p>
</li>
<li><p><strong>INFO</strong>: 一般信息</p>
</li>
<li><p><strong>DEBUG</strong>: 调试信息</p>
</li>
</ul>
<p>  默认的日志等级是DEBUG,只要出现了DEBUG或者DEBUG以上等级的日志,那么这些日志将会打印</p>
</li>
<li><p><code>settings.py</code>文件设置:</p>
<p>  默认的级别为 DEBUG，会显示上面所有的信息</p>
<p>  在配置文件中settings.py</p>
<p>  LOG FILE: 将屏幕显示的信息全部记录到文件中，屏幕不再显示，注意文件后缀一定是<code>.log</code></p>
<p>  LOG LEVEL: 设置日志显示的等级，就是显示哪些，不显示哪些</p>
</li>
</ul>
<h2 id="scrapy的post请求"><a href="#scrapy的post请求" class="headerlink" title="scrapy的post请求"></a>scrapy的post请求</h2><ol>
<li>scrapy中post请求是通过<code>spider/你定义的爬虫程序名.py</code>的<code>start_request()</code>方法实现的</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># post请求 如果没有参数 那么这个请求将没有任何意义</span>
<span class="token comment"># 所以start urls 也没有用了</span>
<span class="token comment"># parse方法也没有用了</span>
<span class="token comment"># start_urls = ['https://fanyi.baidu.com/sug/']</span>
<span class="token comment"># def parse(self, response):</span>
<span class="token comment"># pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ol start="2">
<li>重写start_requests方法:</li>
</ol>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    url <span class="token operator">=</span>'https<span class="token punctuation">:</span><span class="token operator">//</span>fanyi<span class="token punctuation">.</span>baidu<span class="token punctuation">.</span>com<span class="token operator">/</span>sug
    data<span class="token operator">=</span><span class="token punctuation">&#123;</span>
        <span class="token string">'kw'</span><span class="token punctuation">:</span><span class="token string">'final'</span><span class="token punctuation">&#125;</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span>formdata<span class="token operator">=</span>data<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_second<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">parse_second</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ol start="3">
<li>start requests的返回值:</li>
</ol>
<p><code>scrapy.FormRequest(url=url.headers=headers, callback=self.parse_second, formdata=data)</code></p>
<ul>
<li>url: 要发送的post地址</li>
<li>headers: 可以定制头信息</li>
<li>callback: 回调函数</li>
<li>formdata: post所携带的数据，这是一个字典</li>
</ul>
<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>到<strong>settings.py</strong>中，打开一个选项<code>DOWNLOADER MIDDLEWARES=&#123;postproject.middlewares.Proxy&#39;:543,&#125;</code></p>
<p>到<strong>middlewares.py</strong>中写代码</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
	request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'https://113.68.202.10:9999'</span>
	<span class="token keyword">return</span> <span class="token boolean">None</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>




                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">0zxm</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://0zxm.github.io/2024/08/04/scrapy-kuang-jia/">https://0zxm.github.io/2024/08/04/scrapy-kuang-jia/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">0zxm</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/python/">
                                    <span class="chip bg-color">python</span>
                                </a>
                            
                                <a href="/tags/scrapy/">
                                    <span class="chip bg-color">scrapy</span>
                                </a>
                            
                                <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/">
                                    <span class="chip bg-color">数据持久化存储</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/08/13/pyinstaller-shi-yong/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/16.jpg" class="responsive-img" alt="pyinstaller使用">
                        
                        <span class="card-title">pyinstaller使用</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            pyinstaller使用入门
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-08-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/python/" class="post-category">
                                    python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%89%93%E5%8C%85%E7%A8%8B%E5%BA%8F/">
                        <span class="chip bg-color">打包程序</span>
                    </a>
                    
                    <a href="/tags/pyinstaller/">
                        <span class="chip bg-color">pyinstaller</span>
                    </a>
                    
                    <a href="/tags/pyqt/">
                        <span class="chip bg-color">pyqt</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/07/19/javascript-ji-chu-he-pythonweb-kai-fa/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="JavaScript基础和pythonWeb开发">
                        
                        <span class="card-title">JavaScript基础和pythonWeb开发</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            javascript笔记
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-07-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%89%8D%E7%AB%AF/" class="post-category">
                                    前端
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/JavaScript/">
                        <span class="chip bg-color">JavaScript</span>
                    </a>
                    
                    <a href="/tags/json/">
                        <span class="chip bg-color">json</span>
                    </a>
                    
                    <a href="/tags/ajax/">
                        <span class="chip bg-color">ajax</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        font-size: 15px;
        color: #0019ED;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="3177534452"
                   fixed='true'
                   autoplay='false'
                   theme='#0019ED'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <span id="year">2024</span>
            <a href="/about" target="_blank">0zxm</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">418.3k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/0zxm" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:m15813109801@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2378173954" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2378173954" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
